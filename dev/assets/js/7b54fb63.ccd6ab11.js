"use strict";(self.webpackChunkmydevdocs=self.webpackChunkmydevdocs||[]).push([[606],{1454:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"Python/Gemini/Api/chat-api","title":"AI Chat Sessions","description":"The chats.py module, part of the google.genai library, is designed to facilitate and manage multi-turn conversations (chat sessions) with a Generative AI model, such as Google\'s Gemini. It abstracts away the complexities of managing conversation history, sending messages, and processing responses, providing a higher-level interface for building conversational AI applications.","source":"@site/docs/Python/Gemini/Api/chat-api.md","sourceDirName":"Python/Gemini/Api","slug":"/Python/Gemini/Api/chat-api","permalink":"/dev/docs/Python/Gemini/Api/chat-api","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"python","permalink":"/dev/docs/tags/python"},{"inline":true,"label":"generative-ai","permalink":"/dev/docs/tags/generative-ai"},{"inline":true,"label":"chatbots","permalink":"/dev/docs/tags/chatbots"},{"inline":true,"label":"api-client","permalink":"/dev/docs/tags/api-client"},{"inline":true,"label":"conversational-ai","permalink":"/dev/docs/tags/conversational-ai"}],"version":"current","sidebarPosition":1,"frontMatter":{"title":"AI Chat Sessions","sidebar_position":1,"tags":["python","generative-ai","chatbots","api-client","conversational-ai"]},"sidebar":"tutorialSidebar","previous":{"title":"Extensible AI Chat Structure","permalink":"/dev/docs/Python/Chatbot/chat-with-different-ai-api"},"next":{"title":"Conversational AI","permalink":"/dev/docs/Python/Gemini/Api/chat-conversation"}}');var t=s(4848),r=s(8453);const o={title:"AI Chat Sessions",sidebar_position:1,tags:["python","generative-ai","chatbots","api-client","conversational-ai"]},a=void 0,l={},c=[{value:"Core Purpose",id:"core-purpose",level:3},{value:"Key Classes and Their Functionality",id:"key-classes-and-their-functionality",level:3},{value:"Use Cases",id:"use-cases",level:3},{value:"Example Usage (from comments)",id:"example-usage-from-comments",level:3}];function d(e){const n={code:"code",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"chats.py"})," module, part of the ",(0,t.jsx)(n.code,{children:"google.genai"})," library, is designed to facilitate and manage multi-turn conversations (chat sessions) with a Generative AI model, such as Google's Gemini. It abstracts away the complexities of managing conversation history, sending messages, and processing responses, providing a higher-level interface for building conversational AI applications."]}),"\n",(0,t.jsx)(n.h3,{id:"core-purpose",children:"Core Purpose"}),"\n",(0,t.jsx)(n.p,{children:"The primary purpose of this module is to enable developers to create and manage persistent chat sessions with a large language model (LLM). This includes:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Maintaining Conversation History:"})," Automatically keeps track of user inputs and model responses, ensuring that each subsequent turn in the conversation has the necessary context."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sending Messages:"})," Provides methods to send messages to the AI model within a chat session."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Handling Responses:"})," Manages the retrieval and processing of model responses, including streaming responses."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"History Validation:"}),' Incorporates logic to validate the integrity and structure of content within the conversation history, distinguishing between "comprehensive" (all interactions) and "curated" (valid turns for context) history.']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Asynchronous Operations:"})," Offers both synchronous (",(0,t.jsx)(n.code,{children:"Chat"}),") and asynchronous (",(0,t.jsx)(n.code,{children:"AsyncChat"}),") interfaces for flexible integration into different application architectures."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"key-classes-and-their-functionality",children:"Key Classes and Their Functionality"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"_BaseChat"})}),": An abstract base class that encapsulates the common logic for managing chat history, including:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"_comprehensive_history"}),": Stores all turns of the chat, including potentially invalid or rejected model outputs."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"_curated_history"}),": Stores only the valid turns that are used as context for subsequent model requests. This is crucial for maintaining coherent conversations."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"record_history()"}),": Adds new user inputs and model outputs to both histories, validating the model's output."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"get_history()"}),": Allows retrieval of either the comprehensive or curated history."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"Chat"})}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Synchronous Chat Session"}),": Represents a single, synchronous chat session with a Generative AI model."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"send_message(message, config=None)"}),": Sends a user message and returns the model's complete response in a blocking call. The chat history (curated) is automatically included as context."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"send_message_stream(message, config=None)"}),": Sends a user message and yields the model's response in chunks (streaming). This is useful for displaying partial responses as they are generated."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"AsyncChat"})}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Asynchronous Chat Session"}),": Similar to ",(0,t.jsx)(n.code,{children:"Chat"}),", but provides asynchronous methods (",(0,t.jsx)(n.code,{children:"async def"}),") for non-blocking operations, suitable for web servers, UIs, or other async frameworks."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"await send_message(message, config=None)"}),": Asynchronous version of ",(0,t.jsx)(n.code,{children:"send_message"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"async for chunk in await send_message_stream(message, config=None)"}),": Asynchronous version of ",(0,t.jsx)(n.code,{children:"send_message_stream"}),"."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"Chats"})}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Synchronous Chat Factory"}),": A utility class to create new ",(0,t.jsx)(n.code,{children:"Chat"})," instances. It takes an underlying ",(0,t.jsx)(n.code,{children:"Models"})," object (which handles the actual API calls to the generative model)."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"create(model, config=None, history=None)"}),": Instantiates and returns a new ",(0,t.jsx)(n.code,{children:"Chat"})," object, initialized with a specified model and optional initial history."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"AsyncChats"})}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Asynchronous Chat Factory"}),": Similar to ",(0,t.jsx)(n.code,{children:"Chats"}),", but creates ",(0,t.jsx)(n.code,{children:"AsyncChat"})," instances, taking an ",(0,t.jsx)(n.code,{children:"AsyncModels"})," object."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"create(model, config=None, history=None)"}),": Instantiates and returns a new ",(0,t.jsx)(n.code,{children:"AsyncChat"})," object."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"use-cases",children:"Use Cases"}),"\n",(0,t.jsx)(n.p,{children:"This module is fundamental for any application that requires interactive, multi-turn conversations with a Generative AI model."}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Building Conversational AI Agents/Chatbots"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Customer Support Bots"}),": Automatically answer common questions, escalate to human agents when needed, and maintain context across a user's queries."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Virtual Assistants"}),": Provide information, perform tasks, and engage in free-form conversation."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Interactive Storytelling/Gaming"}),": Create dynamic narratives where the AI's responses evolve based on player input."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Content Generation with Context"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Creative Writing Assistants"}),": Assist writers by generating text, brainstorming ideas, or refining content, remembering previous turns and prompts."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Code Generation Tools"}),": Help developers by generating code snippets or explaining concepts in a conversational manner, keeping track of the project's context."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Educational Tools"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Personalized Tutors"}),": Provide explanations and answer questions in an ongoing dialogue, adapting to the student's learning pace and previous interactions."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Language Learning Apps"}),": Engage users in conversational practice, correcting grammar or suggesting vocabulary."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Data Exploration and Analysis (Conversational Interface)"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Allow users to query data or generate reports through natural language conversation, where follow-up questions leverage the context of previous queries."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Interactive Development Environments"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Integrate directly into IDEs or command-line tools to provide AI assistance that understands the ongoing coding context."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"example-usage-from-comments",children:"Example Usage (from comments)"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Synchronous Chat:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import google.generativeai as genai\r\n\r\n# Assuming 'client' is an initialized genai client\r\nclient = genai.GenerativeModel('gemini-pro') # Placeholder for actual client initialization\r\nchat = client.chats.create(model='gemini-pro') # Using client.chats.create\r\nresponse = chat.send_message('tell me a story')\r\nprint(response.text)\r\n\r\n# Streaming response\r\nfor chunk in chat.send_message_stream('continue the story'):\r\n  print(chunk.text, end='')\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Asynchronous Chat:"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import google.generativeai as genai\r\n\r\n# Assuming 'client.aio' is an initialized asynchronous client\r\nasync_client = genai.AsyncGenerativeModel('gemini-pro') # Placeholder for actual client initialization\r\nchat = async_client.aio.chats.create(model='gemini-pro') # Using client.aio.chats.create\r\nresponse = await chat.send_message('tell me a story')\r\nprint(response.text)\r\n\r\n# Streaming response asynchronously\r\nasync for chunk in await chat.send_message_stream('continue the story'):\r\n  print(chunk.text, end='')\n"})}),"\n",(0,t.jsxs)(n.p,{children:["In essence, ",(0,t.jsx)(n.code,{children:"chats.py"})," provides the foundational building blocks for creating stateful, interactive, and intelligent conversational experiences powered by Google's Generative AI models."]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>o,x:()=>a});var i=s(6540);const t={},r=i.createContext(t);function o(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);