"use strict";(self.webpackChunkmydevdocs=self.webpackChunkmydevdocs||[]).push([[8785],{4249:e=>{e.exports=JSON.parse('{"tag":{"label":"token limits","permalink":"/dev/docs/tags/token-limits","allTagsPath":"/dev/docs/tags","count":2,"items":[{"id":"tech-related/Chatbot/understand-models-max-token","title":"Max Token","description":"When interacting with AI models like OpenAI\'s GPT through APIs, understanding how tokens work is essential for optimizing performance, controlling costs, and ensuring reliable responses\u2014especially when generating code.","permalink":"/dev/docs/tech-related/Chatbot/understand-models-max-token"},{"id":"tech-related/Chatbot/optimize-chat-memory-limit-token-reached","title":"Token Limit Management","description":"When working with large language model (LLM) APIs such as OpenAI\u2019s gpt-4, each API call is subject to a maximum token limit (e.g., 8192 or 128k tokens). As conversations grow longer, especially when maintaining history for context, you may quickly approach or exceed these limits.","permalink":"/dev/docs/tech-related/Chatbot/optimize-chat-memory-limit-token-reached"}],"unlisted":false}}')}}]);