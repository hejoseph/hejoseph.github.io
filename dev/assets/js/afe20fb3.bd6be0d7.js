"use strict";(self.webpackChunkmydevdocs=self.webpackChunkmydevdocs||[]).push([[5711],{5739:(e,o,n)=>{n.r(o),n.d(o,{assets:()=>t,contentTitle:()=>l,default:()=>u,frontMatter:()=>d,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"tech-related/Huggingface/Models/models-payload","title":"Hugging Face Model Security","description":"1. Can Anyone Upload Models to Hugging Face?","source":"@site/docs/tech-related/Huggingface/Models/models-payload.md","sourceDirName":"tech-related/Huggingface/Models","slug":"/tech-related/Huggingface/Models/models-payload","permalink":"/dev/docs/tech-related/Huggingface/Models/models-payload","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"huggingface","permalink":"/dev/docs/tags/huggingface"},{"inline":true,"label":"model security","permalink":"/dev/docs/tags/model-security"},{"inline":true,"label":"machine learning","permalink":"/dev/docs/tags/machine-learning"}],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Hugging Face Model Security","sidebar_position":3,"tags":["huggingface","model security","machine learning"]},"sidebar":"tutorialSidebar","previous":{"title":"Model Risks","permalink":"/dev/docs/tech-related/Huggingface/Models/huggingface-models-danger"},"next":{"title":"Hugging Face Model Hosting","permalink":"/dev/docs/tech-related/Huggingface/Models/models-api"}}');var i=n(4848),r=n(8453);const d={title:"Hugging Face Model Security",sidebar_position:3,tags:["huggingface","model security","machine learning"]},l="Hugging Face Model Uploads & Security",t={},c=[{value:"1. <strong>Can Anyone Upload Models to Hugging Face?</strong>",id:"1-can-anyone-upload-models-to-hugging-face",level:2},{value:"2. <strong>How Can Uploaded Models Pose Security Risks?</strong>",id:"2-how-can-uploaded-models-pose-security-risks",level:2},{value:"3. <strong>How Is a &quot;Payload&quot; Set and Run?</strong>",id:"3-how-is-a-payload-set-and-run",level:2},{value:"4. <strong>How to Stay Safe</strong>",id:"4-how-to-stay-safe",level:2},{value:"5. <strong>Summary</strong>",id:"5-summary",level:2}];function a(e){const o={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(o.header,{children:(0,i.jsx)(o.h1,{id:"hugging-face-model-uploads--security",children:"Hugging Face Model Uploads & Security"})}),"\n",(0,i.jsxs)(o.h2,{id:"1-can-anyone-upload-models-to-hugging-face",children:["1. ",(0,i.jsx)(o.strong,{children:"Can Anyone Upload Models to Hugging Face?"})]}),"\n",(0,i.jsx)(o.p,{children:"Yes, Hugging Face allows anyone with an account to upload models, datasets, or other assets to the Hugging Face Hub. These can be public or private, depending on the user's choice. Uploaded models are not automatically vetted or scanned for malicious content."}),"\n",(0,i.jsxs)(o.h2,{id:"2-how-can-uploaded-models-pose-security-risks",children:["2. ",(0,i.jsx)(o.strong,{children:"How Can Uploaded Models Pose Security Risks?"})]}),"\n",(0,i.jsx)(o.p,{children:"Malicious actors can upload models with harmful code in several ways:"}),"\n",(0,i.jsxs)(o.ul,{children:["\n",(0,i.jsxs)(o.li,{children:["\n",(0,i.jsxs)(o.p,{children:[(0,i.jsx)(o.strong,{children:"Custom Code in Model Repositories:"})," Many models include a ",(0,i.jsx)(o.code,{children:"model.py"}),", ",(0,i.jsx)(o.code,{children:"tokenizer.py"})," or a ",(0,i.jsx)(o.code,{children:"README.md"})," with example code. If a user runs code directly from these files (for instance, by following a ",(0,i.jsx)(o.code,{children:"from_pretrained"})," example with ",(0,i.jsx)(o.code,{children:"trust_remote_code=True"}),"), arbitrary Python code from the repository may execute on the machine."]}),"\n"]}),"\n",(0,i.jsxs)(o.li,{children:["\n",(0,i.jsxs)(o.p,{children:[(0,i.jsx)(o.strong,{children:"Pickle Payloads:"})," Some model formats (like PyTorch ",(0,i.jsx)(o.code,{children:".bin"})," files) use the Python ",(0,i.jsx)(o.code,{children:"pickle"})," serialization mechanism. Loading pickled files from untrusted sources can execute embedded code, potentially compromising your system."]}),"\n"]}),"\n",(0,i.jsxs)(o.li,{children:["\n",(0,i.jsxs)(o.p,{children:[(0,i.jsx)(o.strong,{children:"Custom Pipelines:"})," Some models require custom pipeline code, which may be downloaded and executed if ",(0,i.jsx)(o.code,{children:"trust_remote_code"})," is enabled."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(o.h2,{id:"3-how-is-a-payload-set-and-run",children:["3. ",(0,i.jsx)(o.strong,{children:'How Is a "Payload" Set and Run?'})]}),"\n",(0,i.jsx)(o.p,{children:"A payload is malicious code embedded in the model repository. Attackers might:"}),"\n",(0,i.jsxs)(o.ul,{children:["\n",(0,i.jsx)(o.li,{children:"Modify model files or example scripts to include harmful code."}),"\n",(0,i.jsx)(o.li,{children:"Embed malicious logic in model weights (with pickle)."}),"\n",(0,i.jsxs)(o.li,{children:["Rely on users enabling ",(0,i.jsx)(o.code,{children:"trust_remote_code=True"}),", which lets Hugging Face download and execute remote code for custom models."]}),"\n"]}),"\n",(0,i.jsx)(o.p,{children:(0,i.jsx)(o.strong,{children:"Example:"})}),"\n",(0,i.jsx)(o.pre,{children:(0,i.jsx)(o.code,{className:"language-python",children:'from transformers import AutoModel\r\n\r\n# WARNING: trust_remote_code=True can execute arbitrary code from the model repo!\r\nmodel = AutoModel.from_pretrained("malicious-user/malicious-model", trust_remote_code=True)\n'})}),"\n",(0,i.jsxs)(o.p,{children:["If the model repo has a custom Python script (e.g., ",(0,i.jsx)(o.code,{children:"modeling_malicious.py"}),"), this code will be executed."]}),"\n",(0,i.jsxs)(o.h2,{id:"4-how-to-stay-safe",children:["4. ",(0,i.jsx)(o.strong,{children:"How to Stay Safe"})]}),"\n",(0,i.jsxs)(o.ul,{children:["\n",(0,i.jsx)(o.li,{children:(0,i.jsxs)(o.strong,{children:["Never set ",(0,i.jsx)(o.code,{children:"trust_remote_code=True"})," unless you trust the source."]})}),"\n",(0,i.jsx)(o.li,{children:"Inspect model repositories and code before using or running any example scripts."}),"\n",(0,i.jsx)(o.li,{children:"Prefer popular or verified models."}),"\n",(0,i.jsx)(o.li,{children:"Avoid running code or loading weights from unknown or untrusted sources."}),"\n"]}),"\n",(0,i.jsxs)(o.h2,{id:"5-summary",children:["5. ",(0,i.jsx)(o.strong,{children:"Summary"})]}),"\n",(0,i.jsxs)(o.ul,{children:["\n",(0,i.jsx)(o.li,{children:"Anyone can upload models to Hugging Face."}),"\n",(0,i.jsx)(o.li,{children:"Malicious code can be embedded in model files, custom scripts, or pickled weights."}),"\n",(0,i.jsxs)(o.li,{children:["Only use ",(0,i.jsx)(o.code,{children:"trust_remote_code=True"})," for trusted sources, and always review repository contents before use."]}),"\n"]})]})}function u(e={}){const{wrapper:o}={...(0,r.R)(),...e.components};return o?(0,i.jsx)(o,{...e,children:(0,i.jsx)(a,{...e})}):a(e)}},8453:(e,o,n)=>{n.d(o,{R:()=>d,x:()=>l});var s=n(6540);const i={},r=s.createContext(i);function d(e){const o=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(o):{...o,...e}}),[o,e])}function l(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:d(e.components),s.createElement(r.Provider,{value:o},e.children)}}}]);