"use strict";(self.webpackChunkmydevdocs=self.webpackChunkmydevdocs||[]).push([[7573],{1190:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>r});const s=JSON.parse('{"id":"tech-related/Chatbot/understand-models-token","title":"Token Counts in AI","description":"Understanding AI Model Token Counts","source":"@site/docs/tech-related/Chatbot/understand-models-token.md","sourceDirName":"tech-related/Chatbot","slug":"/tech-related/Chatbot/understand-models-token","permalink":"/dev/docs/tech-related/Chatbot/understand-models-token","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"ai models","permalink":"/dev/docs/tags/ai-models"},{"inline":true,"label":"tokens","permalink":"/dev/docs/tags/tokens"},{"inline":true,"label":"input/output size","permalink":"/dev/docs/tags/input-output-size"}],"version":"current","sidebarPosition":5,"frontMatter":{"title":"Token Counts in AI","sidebar_position":5,"tags":["ai models","tokens","input/output size"]},"sidebar":"tutorialSidebar","previous":{"title":"Token Management","permalink":"/dev/docs/tech-related/Chatbot/models-limit"},"next":{"title":"Clean Code Principles","permalink":"/dev/docs/tech-related/Clean Code/clean-code-basics"}}');var o=t(4848),i=t(8453);const l={title:"Token Counts in AI",sidebar_position:5,tags:["ai models","tokens","input/output size"]},a=void 0,d={},r=[{value:"Understanding AI Model Token Counts",id:"understanding-ai-model-token-counts",level:2},{value:"1. Input Tokens (1049k)",id:"1-input-tokens-1049k",level:3},{value:"2. Output Tokens (33k)",id:"2-output-tokens-33k",level:3},{value:"3. Why Use Tokens?",id:"3-why-use-tokens",level:3},{value:"4. Model Capabilities",id:"4-model-capabilities",level:3},{value:"5. Practical Example",id:"5-practical-example",level:3},{value:"Summary Table",id:"summary-table",level:4}];function u(e){const n={br:"br",h2:"h2",h3:"h3",h4:"h4",hr:"hr",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h2,{id:"understanding-ai-model-token-counts",children:"Understanding AI Model Token Counts"}),"\n",(0,o.jsx)(n.p,{children:'When you read that an AI model has "1049k token input and 33k output," it means:'}),"\n",(0,o.jsx)(n.h3,{id:"1-input-tokens-1049k",children:"1. Input Tokens (1049k)"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Definition:"}),' "Input tokens" refer to the individual pieces of text (such as words or chunks of words) that are fed into the AI model.']}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Value:"}),' "1049k" means 1,049,000 tokens.',"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"For reference, in English, one token is generally about 4 characters or 0.75 words, so 1,049,000 tokens can be a very long text or dataset."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"2-output-tokens-33k",children:"2. Output Tokens (33k)"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Definition:"}),' "Output tokens" are the number of tokens generated by the AI model as its response or result.']}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Value:"}),' "33k" means 33,000 tokens.',"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"This could represent a long passage, multiple paragraphs, or even a structured output depending on the task."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"3-why-use-tokens",children:"3. Why Use Tokens?"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Tokenization"})," is a way for AI models to handle text efficiently."]}),"\n",(0,o.jsx)(n.li,{children:"Tokens standardize the processing of texts, since different languages and scripts split into tokens differently."}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"4-model-capabilities",children:"4. Model Capabilities"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Many AI models (like GPT-4, Gemini, Claude, etc.) have limits on how many total tokens (input + output) they can process at once."}),"\n",(0,o.jsx)(n.li,{children:"Extremely high token input (like 1049k) means the model is analyzing a huge amount of text in one go\u2014much more than typical models, which usually max out at a few thousand tokens."}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"5-practical-example",children:"5. Practical Example"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"If you upload a large book (input) and want a summary (output), the large token input would be the book's contents; the output tokens would be the size of the summary generated."}),"\n"]}),"\n",(0,o.jsx)(n.h4,{id:"summary-table",children:"Summary Table"}),"\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"Term"}),(0,o.jsx)(n.th,{children:"Value"}),(0,o.jsx)(n.th,{children:"Meaning"})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"Input Tokens"}),(0,o.jsx)(n.td,{children:"1049k"}),(0,o.jsx)(n.td,{children:"Tokens provided to the model (the context)"})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"Output Tokens"}),(0,o.jsx)(n.td,{children:"33k"}),(0,o.jsx)(n.td,{children:"Tokens generated by the model (the answer)"})]})]})]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"In short:"}),(0,o.jsx)(n.br,{}),"\n",'"1049k token input and 33k output" means the AI model is being given 1,049,000 tokens of information and is generating 33,000 tokens in response. This showcases the processing and generation capabilities of the model.']})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(u,{...e})}):u(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>l,x:()=>a});var s=t(6540);const o={},i=s.createContext(o);function l(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:l(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);