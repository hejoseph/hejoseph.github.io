"use strict";(self.webpackChunkmydevdocs=self.webpackChunkmydevdocs||[]).push([[9872],{3920:e=>{e.exports=JSON.parse('{"tag":{"label":"conversation memory","permalink":"/dev/docs/tags/conversation-memory","allTagsPath":"/dev/docs/tags","count":1,"items":[{"id":"tech-related/Chatbot/optimize-chat-memory-limit-token-reached","title":"Token Limit Management","description":"When working with large language model (LLM) APIs such as OpenAI\u2019s gpt-4, each API call is subject to a maximum token limit (e.g., 8192 or 128k tokens). As conversations grow longer, especially when maintaining history for context, you may quickly approach or exceed these limits.","permalink":"/dev/docs/tech-related/Chatbot/optimize-chat-memory-limit-token-reached"}],"unlisted":false}}')}}]);