"use strict";(self.webpackChunkmydevdocs=self.webpackChunkmydevdocs||[]).push([[3262],{6913:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>d,contentTitle:()=>a,default:()=>p,frontMatter:()=>o,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"Python/Chatbot/chat-with-different-ai-api","title":"Extensible AI Chat Structure","description":"For an extensible chat application where users can choose different AI models (e.g., Gemini, OpenAI, and more in the future), a structured approach using Abstract Base Classes (ABCs) and the Factory Pattern is highly effective. This allows you to define a common interface for all AI providers and easily plug in new ones without modifying existing core logic.","source":"@site/docs/Python/Chatbot/chat-with-different-ai-api.md","sourceDirName":"Python/Chatbot","slug":"/Python/Chatbot/chat-with-different-ai-api","permalink":"/dev/docs/Python/Chatbot/chat-with-different-ai-api","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"python","permalink":"/dev/docs/tags/python"},{"inline":true,"label":"ai","permalink":"/dev/docs/tags/ai"},{"inline":true,"label":"api-integration","permalink":"/dev/docs/tags/api-integration"},{"inline":true,"label":"design-patterns","permalink":"/dev/docs/tags/design-patterns"},{"inline":true,"label":"extensibility","permalink":"/dev/docs/tags/extensibility"}],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Extensible AI Chat Structure","sidebar_position":1,"tags":["python","ai","api-integration","design-patterns","extensibility"]},"sidebar":"tutorialSidebar","previous":{"title":"Naming Conventions","permalink":"/dev/docs/Python/python-naming-convention"},"next":{"title":"AI Chat Sessions","permalink":"/dev/docs/Python/Gemini/Api/chat-api"}}');var s=n(4848),t=n(8453);const o={title:"Extensible AI Chat Structure",sidebar_position:1,tags:["python","ai","api-integration","design-patterns","extensibility"]},a=void 0,d={},l=[{value:"Core Concepts",id:"core-concepts",level:3},{value:"Code Structure",id:"code-structure",level:3},{value:"<code>config.py</code>",id:"configpy",level:3},{value:"<code>ai_providers/abstract_ai_provider.py</code>",id:"ai_providersabstract_ai_providerpy",level:3},{value:"<code>ai_providers/openai_provider.py</code>",id:"ai_providersopenai_providerpy",level:3},{value:"<code>ai_providers/gemini_provider.py</code>",id:"ai_providersgemini_providerpy",level:3},{value:"<code>ai_factory.py</code>",id:"ai_factorypy",level:3},{value:"<code>main.py</code>",id:"mainpy",level:3},{value:"How to Add a New AI API (e.g., <code>ExampleAIProvider</code>)",id:"how-to-add-a-new-ai-api-eg-exampleaiprovider",level:3}];function c(e){const r={code:"code",em:"em",h3:"h3",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(r.p,{children:["For an extensible chat application where users can choose different AI models (e.g., Gemini, OpenAI, and more in the future), a structured approach using ",(0,s.jsx)(r.strong,{children:"Abstract Base Classes (ABCs)"})," and the ",(0,s.jsx)(r.strong,{children:"Factory Pattern"})," is highly effective. This allows you to define a common interface for all AI providers and easily plug in new ones without modifying existing core logic."]}),"\n",(0,s.jsx)(r.h3,{id:"core-concepts",children:"Core Concepts"}),"\n",(0,s.jsxs)(r.ol,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Abstract Base Class (ABC)"}),": Defines the common methods that all AI providers must implement. This enforces a consistent interface."]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Concrete Implementations"}),": Classes for each specific AI provider (e.g., ",(0,s.jsx)(r.code,{children:"GeminiAIProvider"}),", ",(0,s.jsx)(r.code,{children:"OpenAIAIProvider"}),") that inherit from the ABC and implement its methods."]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Factory Pattern"}),': A mechanism to create instances of the AI providers based on a given type (e.g., "gemini", "openai") without exposing the creation logic to the client. This decouples the client from concrete provider classes.']}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Configuration Management"}),": Centralized handling of API keys and default model names, ideally loaded from environment variables for security."]}),"\n"]}),"\n",(0,s.jsx)(r.h3,{id:"code-structure",children:"Code Structure"}),"\n",(0,s.jsx)(r.p,{children:"Here's the recommended file structure and content:"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{children:"project_root/\r\n\u251c\u2500\u2500 config.py\r\n\u251c\u2500\u2500 ai_providers/\r\n\u2502   \u251c\u2500\u2500 __init__.py\r\n\u2502   \u251c\u2500\u2500 abstract_ai_provider.py\r\n\u2502   \u251c\u2500\u2500 gemini_provider.py\r\n\u2502   \u2514\u2500\u2500 openai_provider.py\r\n\u251c\u2500\u2500 ai_factory.py\r\n\u2514\u2500\u2500 main.py\n"})}),"\n",(0,s.jsx)(r.hr,{}),"\n",(0,s.jsx)(r.h3,{id:"configpy",children:(0,s.jsx)(r.code,{children:"config.py"})}),"\n",(0,s.jsx)(r.p,{children:"This file handles loading configuration, especially sensitive API keys, preferably from environment variables."}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-python",children:'import os\r\n\r\nclass Config:\r\n    """Manages application configuration, including API keys and model defaults."""\r\n\r\n    # OpenAI Configuration\r\n    OPENAI_API_KEY: str = os.getenv("OPENAI_API_KEY", "your_openai_api_key_here")\r\n    OPENAI_DEFAULT_MODEL: str = "gpt-3.5-turbo" # Or "gpt-4"\r\n\r\n    # Gemini Configuration\r\n    GEMINI_API_KEY: str = os.getenv("GEMINI_API_KEY", "your_gemini_api_key_here")\r\n    GEMINI_DEFAULT_MODEL: str = "gemini-pro"\r\n\r\n    # Add configuration for other AI providers here\r\n    # EXAMPLE_API_KEY: str = os.getenv("EXAMPLE_API_KEY", "your_example_api_key_here")\r\n    # EXAMPLE_DEFAULT_MODEL: str = "example-model"\r\n\r\n# Example of how to set environment variables (e.g., in your shell or .env file)\r\n# export OPENAI_API_KEY="sk-..."\r\n# export GEMINI_API_KEY="AIza..."\n'})}),"\n",(0,s.jsx)(r.hr,{}),"\n",(0,s.jsx)(r.h3,{id:"ai_providersabstract_ai_providerpy",children:(0,s.jsx)(r.code,{children:"ai_providers/abstract_ai_provider.py"})}),"\n",(0,s.jsx)(r.p,{children:"Defines the common interface for all AI providers."}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-python",children:'from abc import ABC, abstractmethod\r\nfrom typing import List, Dict\r\n\r\nclass AbstractAIProvider(ABC):\r\n    """Abstract Base Class for all AI chat providers."""\r\n\r\n    def __init__(self, api_key: str, model_name: str):\r\n        self._api_key = api_key\r\n        self._model_name = model_name\r\n\r\n    @abstractmethod\r\n    def generate_response(self, messages: List[Dict]) -> str:\r\n        """\r\n        Generates a response from the AI model based on the provided messages.\r\n\r\n        Args:\r\n            messages: A list of message dictionaries, typically in the format\r\n                      `[{"role": "user", "content": "Hello!"}, {"role": "assistant", "content": "Hi!"}]`.\r\n                      The exact format might vary slightly by provider, so concrete\r\n                      implementations should handle conversion if necessary.\r\n\r\n        Returns:\r\n            The AI\'s response as a string.\r\n        """\r\n        pass\r\n\r\n    @abstractmethod\r\n    def get_model_name(self) -> str:\r\n        """Returns the name of the AI model being used."""\r\n        pass\r\n\r\n    # Add other common methods if needed, e.g., get_token_count, get_available_models\n'})}),"\n",(0,s.jsx)(r.hr,{}),"\n",(0,s.jsx)(r.h3,{id:"ai_providersopenai_providerpy",children:(0,s.jsx)(r.code,{children:"ai_providers/openai_provider.py"})}),"\n",(0,s.jsxs)(r.p,{children:["Implements the ",(0,s.jsx)(r.code,{children:"AbstractAIProvider"})," for OpenAI's API.\r\n",(0,s.jsxs)(r.em,{children:["(Install ",(0,s.jsx)(r.code,{children:"openai"})," with ",(0,s.jsx)(r.code,{children:"pip install openai"}),")"]})]}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-python",children:'from openai import OpenAI\r\nfrom typing import List, Dict\r\nfrom .abstract_ai_provider import AbstractAIProvider\r\n\r\nclass OpenAIAIProvider(AbstractAIProvider):\r\n    """Concrete implementation for OpenAI chat models."""\r\n\r\n    def __init__(self, api_key: str, model_name: str):\r\n        super().__init__(api_key, model_name)\r\n        self._client = OpenAI(api_key=self._api_key)\r\n\r\n    def generate_response(self, messages: List[Dict]) -> str:\r\n        """\r\n        Generates a response using OpenAI\'s chat completion API.\r\n        The \'messages\' format is directly compatible with OpenAI\'s API.\r\n        """\r\n        try:\r\n            chat_completion = self._client.chat.completions.create(\r\n                model=self._model_name,\r\n                messages=messages,\r\n                temperature=0.7, # Example parameter\r\n            )\r\n            return chat_completion.choices[0].message.content\r\n        except Exception as e:\r\n            print(f"Error calling OpenAI API: {e}")\r\n            return "Sorry, I couldn\'t get a response from OpenAI."\r\n\r\n    def get_model_name(self) -> str:\r\n        return self._model_name\r\n\n'})}),"\n",(0,s.jsx)(r.hr,{}),"\n",(0,s.jsx)(r.h3,{id:"ai_providersgemini_providerpy",children:(0,s.jsx)(r.code,{children:"ai_providers/gemini_provider.py"})}),"\n",(0,s.jsxs)(r.p,{children:["Implements the ",(0,s.jsx)(r.code,{children:"AbstractAIProvider"})," for Google Gemini's API.\r\n",(0,s.jsxs)(r.em,{children:["(Install ",(0,s.jsx)(r.code,{children:"google-generativeai"})," with ",(0,s.jsx)(r.code,{children:"pip install google-generativeai"}),")"]})]}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-python",children:'import google.generativeai as genai\r\nfrom typing import List, Dict\r\nfrom .abstract_ai_provider import AbstractAIProvider\r\n\r\nclass GeminiAIProvider(AbstractAIProvider):\r\n    """Concrete implementation for Google Gemini chat models."""\r\n\r\n    def __init__(self, api_key: str, model_name: str):\r\n        super().__init__(api_key, model_name)\r\n        genai.configure(api_key=self._api_key)\r\n        self._model = genai.GenerativeModel(self._model_name)\r\n\r\n    def generate_response(self, messages: List[Dict]) -> str:\r\n        """\r\n        Generates a response using Google Gemini\'s chat API.\r\n        Note: Gemini\'s `start_chat` expects messages in a slightly different\r\n        format (e.g., no \'role\' for user/model in history after initial prompt).\r\n        This example simplifies for clarity, assuming a new chat per call or\r\n        a conversion function. For proper continuous chat, you\'d manage `chat_session`.\r\n        """\r\n        try:\r\n            # For simplicity, converting OpenAI-like messages to Gemini\'s format\r\n            # for a single turn. For multi-turn conversations, you\'d manage a chat session.\r\n            gemini_messages = []\r\n            for msg in messages:\r\n                role_map = {"user": "user", "assistant": "model"}\r\n                gemini_messages.append({"role": role_map.get(msg["role"], "user"), "parts": [msg["content"]]})\r\n\r\n            # For a single request, the last message is the prompt.\r\n            # For continuous chat, use `start_chat` and `send_message`.\r\n            response = self._model.generate_content(gemini_messages[-1]["parts"][0]) # Take the last user message\r\n            return response.text\r\n        except Exception as e:\r\n            print(f"Error calling Gemini API: {e}")\r\n            return "Sorry, I couldn\'t get a response from Gemini."\r\n\r\n    def get_model_name(self) -> str:\r\n        return self._model_name\r\n\n'})}),"\n",(0,s.jsx)(r.hr,{}),"\n",(0,s.jsx)(r.h3,{id:"ai_factorypy",children:(0,s.jsx)(r.code,{children:"ai_factory.py"})}),"\n",(0,s.jsx)(r.p,{children:"The factory that provides instances of AI providers based on a string identifier."}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-python",children:'from typing import Type\r\nfrom ai_providers.abstract_ai_provider import AbstractAIProvider\r\nfrom ai_providers.openai_provider import OpenAIAIProvider\r\nfrom ai_providers.gemini_provider import GeminiAIProvider\r\nfrom config import Config\r\n\r\nclass AIProviderFactory:\r\n    """Factory for creating AI provider instances."""\r\n\r\n    _providers: dict[str, Type[AbstractAIProvider]] = {\r\n        "openai": OpenAIAIProvider,\r\n        "gemini": GeminiAIProvider,\r\n        # Add new AI providers here\r\n        # "example_ai": ExampleAIProvider,\r\n    }\r\n\r\n    @staticmethod\r\n    def get_provider(provider_name: str) -> AbstractAIProvider:\r\n        """\r\n        Returns an instance of the specified AI provider.\r\n\r\n        Args:\r\n            provider_name: The name of the AI provider (e.g., "openai", "gemini").\r\n\r\n        Returns:\r\n            An instance of AbstractAIProvider.\r\n\r\n        Raises:\r\n            ValueError: If the provider name is not recognized.\r\n        """\r\n        provider_class = AIProviderFactory._providers.get(provider_name.lower())\r\n\r\n        if not provider_class:\r\n            raise ValueError(f"Unknown AI provider: {provider_name}. Available providers: {list(AIProviderFactory._providers.keys())}")\r\n\r\n        # Retrieve API key and model name from Config based on provider_name\r\n        api_key = getattr(Config, f"{provider_name.upper()}_API_KEY")\r\n        model_name = getattr(Config, f"{provider_name.upper()}_DEFAULT_MODEL")\r\n\r\n        return provider_class(api_key=api_key, model_name=model_name)\r\n\n'})}),"\n",(0,s.jsx)(r.hr,{}),"\n",(0,s.jsx)(r.h3,{id:"mainpy",children:(0,s.jsx)(r.code,{children:"main.py"})}),"\n",(0,s.jsx)(r.p,{children:"The main application logic, demonstrating how to use the factory to interact with different AI models."}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-python",children:'from ai_factory import AIProviderFactory\r\nfrom typing import List, Dict\r\n\r\ndef chat_interface():\r\n    """Simple command-line chat interface."""\r\n    print("Welcome to the Multi-AI Chatbot!")\r\n    print("Choose your AI provider (e.g., openai, gemini):")\r\n\r\n    provider_choice = input("> ").strip().lower()\r\n\r\n    try:\r\n        ai_provider = AIProviderFactory.get_provider(provider_choice)\r\n        print(f"Using {ai_provider.get_model_name()} via {provider_choice} provider.")\r\n    except ValueError as e:\r\n        print(e)\r\n        return\r\n\r\n    messages: List[Dict] = []\r\n\r\n    print("\\nStart chatting! Type \'quit\' or \'exit\' to end.")\r\n    while True:\r\n        user_input = input("You: ").strip()\r\n\r\n        if user_input.lower() in ["quit", "exit"]:\r\n            print("Goodbye!")\r\n            break\r\n\r\n        messages.append({"role": "user", "content": user_input})\r\n\r\n        print(f"AI ({ai_provider.get_model_name()}): Thinking...", end="\\r")\r\n        ai_response = ai_provider.generate_response(messages)\r\n        print(f"AI ({ai_provider.get_model_name()}): {ai_response}")\r\n\r\n        messages.append({"role": "assistant", "content": ai_response})\r\n\r\n        # Keep messages list short for demo purposes, or implement history management\r\n        if len(messages) > 10:\r\n            messages = messages[-8:] # Keep last 4 turns (user + assistant)\r\n\r\nif __name__ == "__main__":\r\n    # Set environment variables for API keys before running, e.g.:\r\n    # export OPENAI_API_KEY="sk-..."\r\n    # export GEMINI_API_KEY="AIza..."\r\n    #\r\n    # Or modify config.py directly for testing (not recommended for production)\r\n\r\n    chat_interface()\n'})}),"\n",(0,s.jsx)(r.hr,{}),"\n",(0,s.jsxs)(r.h3,{id:"how-to-add-a-new-ai-api-eg-exampleaiprovider",children:["How to Add a New AI API (e.g., ",(0,s.jsx)(r.code,{children:"ExampleAIProvider"}),")"]}),"\n",(0,s.jsxs)(r.ol,{children:["\n",(0,s.jsxs)(r.li,{children:["\n",(0,s.jsxs)(r.p,{children:[(0,s.jsx)(r.strong,{children:"Install SDK"}),": Install the Python SDK for your new AI (e.g., ",(0,s.jsx)(r.code,{children:"pip install example_sdk"}),")."]}),"\n"]}),"\n",(0,s.jsxs)(r.li,{children:["\n",(0,s.jsxs)(r.p,{children:[(0,s.jsxs)(r.strong,{children:["Update ",(0,s.jsx)(r.code,{children:"config.py"})]}),": Add API key and model name configurations."]}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-python",children:'# config.py\r\nclass Config:\r\n    # ... existing config\r\n    EXAMPLE_API_KEY: str = os.getenv("EXAMPLE_API_KEY", "your_example_api_key_here")\r\n    EXAMPLE_DEFAULT_MODEL: str = "example-model-v1"\n'})}),"\n"]}),"\n",(0,s.jsxs)(r.li,{children:["\n",(0,s.jsxs)(r.p,{children:[(0,s.jsxs)(r.strong,{children:["Create ",(0,s.jsx)(r.code,{children:"ai_providers/example_ai_provider.py"})]}),":"]}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:["Create a new file ",(0,s.jsx)(r.code,{children:"example_ai_provider.py"})," in the ",(0,s.jsx)(r.code,{children:"ai_providers"})," directory."]}),"\n",(0,s.jsxs)(r.li,{children:["Import ",(0,s.jsx)(r.code,{children:"AbstractAIProvider"}),"."]}),"\n",(0,s.jsxs)(r.li,{children:["Create a class ",(0,s.jsx)(r.code,{children:"ExampleAIProvider"})," that inherits from ",(0,s.jsx)(r.code,{children:"AbstractAIProvider"}),"."]}),"\n",(0,s.jsxs)(r.li,{children:["Implement the ",(0,s.jsx)(r.code,{children:"__init__"})," and ",(0,s.jsx)(r.code,{children:"generate_response"})," methods according to the new API's SDK. Remember to convert messages to the API's expected format if necessary."]}),"\n",(0,s.jsxs)(r.li,{children:["Implement ",(0,s.jsx)(r.code,{children:"get_model_name"}),"."]}),"\n"]}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-python",children:'# ai_providers/example_ai_provider.py\r\n# from example_sdk import ExampleClient # Hypothetical SDK import\r\nfrom typing import List, Dict\r\nfrom .abstract_ai_provider import AbstractAIProvider\r\n\r\nclass ExampleAIProvider(AbstractAIProvider):\r\n    def __init__(self, api_key: str, model_name: str):\r\n        super().__init__(api_key, model_name)\r\n        # self._client = ExampleClient(api_key=self._api_key) # Initialize SDK client\r\n\r\n    def generate_response(self, messages: List[Dict]) -> str:\r\n        # Convert messages to the format expected by ExampleAIProvider\'s SDK\r\n        # For simplicity, let\'s assume it takes the last user message as a string\r\n        last_user_message = next((m["content"] for m in reversed(messages) if m["role"] == "user"), "")\r\n        if not last_user_message:\r\n            return "No user message provided."\r\n\r\n        try:\r\n            # response = self._client.generate(model=self._model_name, prompt=last_user_message)\r\n            # return response.text # Or whatever the SDK returns\r\n            return f"Response from ExampleAI using model \'{self._model_name}\': {last_user_message.upper()} (simulated)"\r\n        except Exception as e:\r\n            print(f"Error calling ExampleAI API: {e}")\r\n            return "Sorry, I couldn\'t get a response from ExampleAI."\r\n\r\n    def get_model_name(self) -> str:\r\n        return self._model_name\n'})}),"\n"]}),"\n",(0,s.jsxs)(r.li,{children:["\n",(0,s.jsxs)(r.p,{children:[(0,s.jsxs)(r.strong,{children:["Update ",(0,s.jsx)(r.code,{children:"ai_factory.py"})]}),":"]}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsx)(r.li,{children:"Import your new provider class."}),"\n",(0,s.jsxs)(r.li,{children:["Add it to the ",(0,s.jsx)(r.code,{children:"_providers"})," dictionary."]}),"\n"]}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-python",children:'# ai_factory.py\r\n# ... existing imports\r\nfrom ai_providers.example_ai_provider import ExampleAIProvider # New import\r\n\r\nclass AIProviderFactory:\r\n    _providers: dict[str, Type[AbstractAIProvider]] = {\r\n        "openai": OpenAIAIProvider,\r\n        "gemini": GeminiAIProvider,\r\n        "example_ai": ExampleAIProvider, # Add new provider here\r\n    }\r\n    # ... rest of the class\n'})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(r.p,{children:["Now, when you run ",(0,s.jsx)(r.code,{children:"main.py"}),", you can type ",(0,s.jsx)(r.code,{children:"example_ai"})," as your choice, and the system will instantiate and use your new AI provider without any changes to ",(0,s.jsx)(r.code,{children:"main.py"})," itself."]})]})}function p(e={}){const{wrapper:r}={...(0,t.R)(),...e.components};return r?(0,s.jsx)(r,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,r,n)=>{n.d(r,{R:()=>o,x:()=>a});var i=n(6540);const s={},t=i.createContext(s);function o(e){const r=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(r):{...r,...e}}),[r,e])}function a(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(t.Provider,{value:r},e.children)}}}]);