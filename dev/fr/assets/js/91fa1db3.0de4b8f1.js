"use strict";(self.webpackChunkmydevdocs=self.webpackChunkmydevdocs||[]).push([[8776],{7462:e=>{e.exports=JSON.parse('{"tag":{"label":"LLM","permalink":"/dev/fr/docs/tags/llm","allTagsPath":"/dev/fr/docs/tags","count":3,"items":[{"id":"Python/Openai/Api/openai-use-case","title":"Exemples d\'API OpenAI","description":"Voici des exemples concrets pour les cas d\'utilisation courants de l\'API OpenAI :","permalink":"/dev/fr/docs/Python/Openai/Api/openai-use-case"},{"id":"tech-related/Chatbot/optimize-chat-memory-limit-token-reached","title":"Gestion des Limites de Tokens","description":"Lors de l\u2019utilisation d\u2019API de mod\xe8les de langage (LLM) comme OpenAI GPT-4, chaque appel API est soumis \xe0 une limite maximale de tokens (par exemple, 8192 ou 128k tokens). Les conversations longues d\xe9passent facilement cette limite, surtout si l\u2019on conserve l\u2019historique pour assurer la continuit\xe9.","permalink":"/dev/fr/docs/tech-related/Chatbot/optimize-chat-memory-limit-token-reached"},{"id":"Python/Openai/Api/openai-api-intro","title":"Utilisations de l\'API OpenAI","description":"La structure du client API OpenAI fournie r\xe9v\xe8le plusieurs cas d\'utilisation courants pour interagir avec les mod\xe8les d\'OpenAI :","permalink":"/dev/fr/docs/Python/Openai/Api/openai-api-intro"}],"unlisted":false}}')}}]);