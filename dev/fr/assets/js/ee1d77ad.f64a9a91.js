"use strict";(self.webpackChunkmydevdocs=self.webpackChunkmydevdocs||[]).push([[5567],{5399:e=>{e.exports=JSON.parse('{"tag":{"label":"gestion de contexte","permalink":"/dev/fr/docs/tags/gestion-de-contexte","allTagsPath":"/dev/fr/docs/tags","count":1,"items":[{"id":"tech-related/Chatbot/optimize-chat-memory-limit-token-reached","title":"Gestion des Limites de Tokens","description":"Lors de l\u2019utilisation d\u2019API de mod\xe8les de langage (LLM) comme OpenAI GPT-4, chaque appel API est soumis \xe0 une limite maximale de tokens (par exemple, 8192 ou 128k tokens). Les conversations longues d\xe9passent facilement cette limite, surtout si l\u2019on conserve l\u2019historique pour assurer la continuit\xe9.","permalink":"/dev/fr/docs/tech-related/Chatbot/optimize-chat-memory-limit-token-reached"}],"unlisted":false}}')}}]);