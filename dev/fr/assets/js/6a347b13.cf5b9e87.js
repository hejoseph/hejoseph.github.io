"use strict";(self.webpackChunkmydevdocs=self.webpackChunkmydevdocs||[]).push([[4606],{1054:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>u,frontMatter:()=>o,metadata:()=>i,toc:()=>a});const i=JSON.parse('{"id":"Python/Gemini/Api/chat-api","title":"Sessions de discussion IA","description":"Le module chats.py, qui fait partie de la biblioth\xe8que google.genai, est con\xe7u pour faciliter et g\xe9rer les conversations multi-tours (sessions de chat) avec un mod\xe8le d\'IA g\xe9n\xe9rative, tel que Gemini de Google. Il masque les complexit\xe9s li\xe9es \xe0 la gestion de l\'historique des conversations, \xe0 l\'envoi de messages et au traitement des r\xe9ponses, en offrant une interface de plus haut niveau pour la cr\xe9ation d\'applications d\'IA conversationnelle.","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/Python/Gemini/Api/chat-api.md","sourceDirName":"Python/Gemini/Api","slug":"/Python/Gemini/Api/chat-api","permalink":"/dev/fr/docs/Python/Gemini/Api/chat-api","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Sessions de discussion IA","sidebar_position":1,"balises":["python","generative-ai","chatbots","api-client","conversational-ai"]},"sidebar":"tutorialSidebar","previous":{"title":"Structure de Chat IA Extensible","permalink":"/dev/fr/docs/Python/Chatbot/chat-with-different-ai-api"},"next":{"title":"IA conversationnelle","permalink":"/dev/fr/docs/Python/Gemini/Api/chat-conversation"}}');var t=s(4848),r=s(8453);const o={title:"Sessions de discussion IA",sidebar_position:1,balises:["python","generative-ai","chatbots","api-client","conversational-ai"]},l=void 0,c={},a=[{value:"Objectif principal",id:"objectif-principal",level:3},{value:"Classes cl\xe9s et leurs fonctionnalit\xe9s",id:"classes-cl\xe9s-et-leurs-fonctionnalit\xe9s",level:3},{value:"Cas d&#39;utilisation",id:"cas-dutilisation",level:3},{value:"Exemple d&#39;utilisation (issu des commentaires)",id:"exemple-dutilisation-issu-des-commentaires",level:3}];function d(e){const n={code:"code",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.p,{children:["Le module ",(0,t.jsx)(n.code,{children:"chats.py"}),", qui fait partie de la biblioth\xe8que ",(0,t.jsx)(n.code,{children:"google.genai"}),", est con\xe7u pour faciliter et g\xe9rer les conversations multi-tours (sessions de chat) avec un mod\xe8le d'IA g\xe9n\xe9rative, tel que Gemini de Google. Il masque les complexit\xe9s li\xe9es \xe0 la gestion de l'historique des conversations, \xe0 l'envoi de messages et au traitement des r\xe9ponses, en offrant une interface de plus haut niveau pour la cr\xe9ation d'applications d'IA conversationnelle."]}),"\n",(0,t.jsx)(n.h3,{id:"objectif-principal",children:"Objectif principal"}),"\n",(0,t.jsx)(n.p,{children:"L'objectif principal de ce module est de permettre aux d\xe9veloppeurs de cr\xe9er et de g\xe9rer des sessions de discussion persistantes avec un grand mod\xe8le linguistique (LLM). Cela comprend :"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Gestion de l'historique de conversation"})," : Il assure automatiquement le suivi des entr\xe9es utilisateur et des r\xe9ponses du mod\xe8le, garantissant que chaque tour de conversation ult\xe9rieur dispose du contexte n\xe9cessaire."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Envoi de messages"})," : Il fournit des m\xe9thodes pour envoyer des messages au mod\xe8le d'IA au sein d'une session de discussion."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Gestion des r\xe9ponses"})," : Il g\xe8re la r\xe9cup\xe9ration et le traitement des r\xe9ponses du mod\xe8le, y compris les r\xe9ponses en flux continu."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Validation de l'historique"})," : Il int\xe8gre une logique pour valider l'int\xe9grit\xe9 et la structure du contenu de l'historique de conversation, en distinguant un historique \xab complet \xbb (toutes les interactions) d'un historique \xab organis\xe9 \xbb (tours valides pour le contexte)."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Op\xe9rations asynchrones"})," : Il offre des interfaces synchrones (",(0,t.jsx)(n.code,{children:"Chat"}),") et asynchrones (",(0,t.jsx)(n.code,{children:"AsyncChat"}),") pour une int\xe9gration flexible dans diff\xe9rentes architectures d'application."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"classes-cl\xe9s-et-leurs-fonctionnalit\xe9s",children:"Classes cl\xe9s et leurs fonctionnalit\xe9s"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"_BaseChat"})})," : Une classe de base abstraite qui encapsule la logique commune de gestion de l'historique de discussion, y compris :"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"_comprehensive_history"})," : Stocke tous les tours de la discussion, y compris les sorties du mod\xe8le potentiellement invalides ou rejet\xe9es."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"_curated_history"})," : Stocke uniquement les tours valides qui sont utilis\xe9s comme contexte pour les requ\xeates ult\xe9rieures du mod\xe8le. Ceci est crucial pour maintenir des conversations coh\xe9rentes."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"record_history()"})," : Ajoute de nouvelles entr\xe9es utilisateur et sorties du mod\xe8le aux deux historiques, en validant la sortie du mod\xe8le."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"get_history()"})," : Permet la r\xe9cup\xe9ration de l'historique complet ou de l'historique organis\xe9."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"Chat"})})," :"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Session de discussion synchrone"})," : Repr\xe9sente une session de discussion unique et synchrone avec un mod\xe8le d'IA g\xe9n\xe9rative."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"send_message(message, config=None)"})," : Envoie un message utilisateur et renvoie la r\xe9ponse compl\xe8te du mod\xe8le dans un appel bloquant. L'historique de discussion (organis\xe9) est automatiquement inclus comme contexte."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"send_message_stream(message, config=None)"})," : Envoie un message utilisateur et fournit la r\xe9ponse du mod\xe8le par morceaux (en flux continu). Ceci est utile pour afficher des r\xe9ponses partielles au fur et \xe0 mesure de leur g\xe9n\xe9ration."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"AsyncChat"})})," :"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Session de discussion asynchrone"})," : Similaire \xe0 ",(0,t.jsx)(n.code,{children:"Chat"}),", mais fournit des m\xe9thodes asynchrones (",(0,t.jsx)(n.code,{children:"async def"}),") pour des op\xe9rations non bloquantes, adapt\xe9es aux serveurs web, aux interfaces utilisateur ou \xe0 d'autres frameworks asynchrones."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"await send_message(message, config=None)"})," : Version asynchrone de ",(0,t.jsx)(n.code,{children:"send_message"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"async for chunk in await send_message_stream(message, config=None)"})," : Version asynchrone de ",(0,t.jsx)(n.code,{children:"send_message_stream"}),"."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"Chats"})})," :"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Fabrique de sessions de discussion synchrone"})," : Une classe utilitaire pour cr\xe9er de nouvelles instances de ",(0,t.jsx)(n.code,{children:"Chat"}),". Elle prend un objet ",(0,t.jsx)(n.code,{children:"Models"})," sous-jacent (qui g\xe8re les appels d'API r\xe9els vers le mod\xe8le g\xe9n\xe9ratif)."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"create(model, config=None, history=None)"})," : Instancie et renvoie un nouvel objet ",(0,t.jsx)(n.code,{children:"Chat"}),", initialis\xe9 avec un mod\xe8le sp\xe9cifi\xe9 et un historique initial facultatif."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.code,{children:"AsyncChats"})})," :"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Fabrique de sessions de discussion asynchrones"})," : Similaire \xe0 ",(0,t.jsx)(n.code,{children:"Chats"}),", mais cr\xe9e des instances de ",(0,t.jsx)(n.code,{children:"AsyncChat"}),", en prenant un objet ",(0,t.jsx)(n.code,{children:"AsyncModels"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"create(model, config=None, history=None)"})," : Instancie et renvoie un nouvel objet ",(0,t.jsx)(n.code,{children:"AsyncChat"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"cas-dutilisation",children:"Cas d'utilisation"}),"\n",(0,t.jsx)(n.p,{children:"Ce module est fondamental pour toute application qui n\xe9cessite des conversations interactives et multi-tours avec un mod\xe8le d'IA g\xe9n\xe9rative."}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Cr\xe9ation d'agents conversationnels IA / de chatbots"})," :"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Bots de support client"})," : R\xe9pondent automatiquement aux questions courantes, escaladent vers des agents humains si n\xe9cessaire, et maintiennent le contexte des requ\xeates d'un utilisateur."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Assistants virtuels"})," : Fournissent des informations, effectuent des t\xe2ches et engagent une conversation libre."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Narration interactive / Jeux"})," : Cr\xe9ent des r\xe9cits dynamiques o\xf9 les r\xe9ponses de l'IA \xe9voluent en fonction des entr\xe9es du joueur."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"G\xe9n\xe9ration de contenu avec contexte"})," :"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Assistants d'\xe9criture cr\xe9ative"})," : Aident les r\xe9dacteurs en g\xe9n\xe9rant du texte, en proposant des id\xe9es ou en affinant le contenu, en se souvenant des tours et des invites pr\xe9c\xe9dents."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Outils de g\xe9n\xe9ration de code"})," : Aident les d\xe9veloppeurs en g\xe9n\xe9rant des extraits de code ou en expliquant des concepts de mani\xe8re conversationnelle, en gardant une trace du contexte du projet."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Outils \xe9ducatifs"})," :"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Tuteurs personnalis\xe9s"})," : Fournissent des explications et r\xe9pondent aux questions dans un dialogue continu, s'adaptant au rythme d'apprentissage de l'\xe9tudiant et aux interactions pr\xe9c\xe9dentes."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Applications d'apprentissage des langues"})," : Engagent les utilisateurs dans une pratique conversationnelle, corrigeant la grammaire ou sugg\xe9rant du vocabulaire."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Exploration et analyse de donn\xe9es (interface conversationnelle)"})," :"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Permettent aux utilisateurs d'interroger des donn\xe9es ou de g\xe9n\xe9rer des rapports via une conversation en langage naturel, o\xf9 les questions de suivi exploitent le contexte des requ\xeates pr\xe9c\xe9dentes."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Environnements de d\xe9veloppement interactifs"})," :"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"S'int\xe8grent directement dans les IDE ou les outils en ligne de commande pour fournir une assistance IA qui comprend le contexte de codage en cours."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"exemple-dutilisation-issu-des-commentaires",children:"Exemple d'utilisation (issu des commentaires)"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Discussion synchrone :"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import google.generativeai as genai\r\n\r\n# Supposons que 'client' est un client genai initialis\xe9\r\nclient = genai.GenerativeModel('gemini-pro') # Espace r\xe9serv\xe9 pour l'initialisation r\xe9elle du client\r\nchat = client.chats.create(model='gemini-pro') # Utilisation de client.chats.create\r\nresponse = chat.send_message('tell me a story')\r\nprint(response.text)\r\n\r\n# R\xe9ponse en flux continu\r\nfor chunk in chat.send_message_stream('continue the story'):\r\n  print(chunk.text, end='')\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Discussion asynchrone :"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import google.generativeai as genai\r\n\r\n# Supposons que 'client.aio' est un client asynchrone initialis\xe9\r\nasync_client = genai.AsyncGenerativeModel('gemini-pro') # Espace r\xe9serv\xe9 pour l'initialisation r\xe9elle du client\r\nchat = async_client.aio.chats.create(model='gemini-pro') # Utilisation de client.aio.chats.create\r\nresponse = await chat.send_message('tell me a story')\r\nprint(response.text)\r\n\r\n# R\xe9ponse en flux continu de mani\xe8re asynchrone\r\nasync for chunk in await chat.send_message_stream('continue the story'):\r\n  print(chunk.text, end='')\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Essentiellement, ",(0,t.jsx)(n.code,{children:"chats.py"})," fournit les blocs de construction fondamentaux pour cr\xe9er des exp\xe9riences conversationnelles intelligentes, interactives et avec \xe9tat, aliment\xe9es par les mod\xe8les d'IA g\xe9n\xe9rative de Google."]})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>o,x:()=>l});var i=s(6540);const t={},r=i.createContext(t);function o(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);