"use strict";(self.webpackChunkmydevdocs=self.webpackChunkmydevdocs||[]).push([[9489],{2586:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>u,frontMatter:()=>l,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"tech-related/Langchain/langchain-benefits","title":"API vs LangChain","description":"Lorsque vous travaillez avec des APIs de mod\xe8les de langage (comme OpenAI, Anthropic ou autres), vous pouvez interagir avec elles soit directement via leurs APIs HTTP, soit indirectement en utilisant un framework tel que LangChain. Voici les principales diff\xe9rences :","source":"@site/i18n/fr/docusaurus-plugin-content-docs/current/tech-related/Langchain/langchain-benefits.md","sourceDirName":"tech-related/Langchain","slug":"/tech-related/Langchain/langchain-benefits","permalink":"/dev/fr/docs/tech-related/Langchain/langchain-benefits","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"langchain","permalink":"/dev/fr/docs/tags/langchain"},{"inline":true,"label":"int\xe9gration api","permalink":"/dev/fr/docs/tags/integration-api"},{"inline":true,"label":"orchestration LLM","permalink":"/dev/fr/docs/tags/orchestration-llm"}],"version":"current","sidebarPosition":5,"frontMatter":{"title":"API vs LangChain","sidebar_position":5,"tags":["langchain","int\xe9gration api","orchestration LLM"]},"sidebar":"tutorialSidebar","previous":{"title":"Flux de travail LangChain","permalink":"/dev/fr/docs/tech-related/Langchain/langchain-how-does-it-work"},"next":{"title":"Acc\xe8s Web Local","permalink":"/dev/fr/docs/tech-related/Networking/server-web-app-local-network"}}');var r=s(4848),t=s(8453);const l={title:"API vs LangChain",sidebar_position:5,tags:["langchain","int\xe9gration api","orchestration LLM"]},a="Diff\xe9rences : Appel API Direct vs Int\xe9gration LangChain",o={},c=[{value:"1. Appel API Direct",id:"1-appel-api-direct",level:2},{value:"2. Utilisation de LangChain",id:"2-utilisation-de-langchain",level:2},{value:"Tableau r\xe9capitulatif",id:"tableau-r\xe9capitulatif",level:2},{value:"Quand utiliser quoi ?",id:"quand-utiliser-quoi-",level:2}];function d(e){const n={br:"br",code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"diff\xe9rences--appel-api-direct-vs-int\xe9gration-langchain",children:"Diff\xe9rences : Appel API Direct vs Int\xe9gration LangChain"})}),"\n",(0,r.jsxs)(n.p,{children:["Lorsque vous travaillez avec des APIs de mod\xe8les de langage (comme OpenAI, Anthropic ou autres), vous pouvez interagir avec elles soit ",(0,r.jsx)(n.strong,{children:"directement"})," via leurs APIs HTTP, soit ",(0,r.jsx)(n.strong,{children:"indirectement"})," en utilisant un framework tel que ",(0,r.jsx)(n.strong,{children:"LangChain"}),". Voici les principales diff\xe9rences :"]}),"\n",(0,r.jsx)(n.h2,{id:"1-appel-api-direct",children:"1. Appel API Direct"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Comment \xe7a fonctionne :"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Votre application envoie des requ\xeates HTTP directement au point de terminaison de l\u2019API du fournisseur de mod\xe8le."}),"\n",(0,r.jsx)(n.li,{children:"Vous g\xe9rez vous-m\xeame l\u2019authentification, la mise en forme de la requ\xeate et l\u2019analyse de la r\xe9ponse."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Avantages :"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Contr\xf4le total sur la charge utile, les en-t\xeates et les param\xe8tres de l\u2019API."}),"\n",(0,r.jsx)(n.li,{children:"L\xe9ger, pas de d\xe9pendances suppl\xe9mentaires."}),"\n",(0,r.jsx)(n.li,{children:"Id\xe9al pour les cas d\u2019usage simples (un seul prompt, une seule r\xe9ponse)."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Inconv\xe9nients :"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Travail manuel requis pour cha\xeener des prompts, la gestion de la m\xe9moire ou l\u2019application d\u2019outils."}),"\n",(0,r.jsx)(n.li,{children:"Vous devez \xe9crire du code suppl\xe9mentaire pour les t\xe2ches avanc\xe9es comme le raisonnement multi-\xe9tapes, l\u2019utilisation d\u2019outils, la g\xe9n\xe9ration augment\xe9e par la r\xe9cup\xe9ration ou l\u2019analyse des sorties."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Exemple (Python avec OpenAI) :"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import openai\r\n\r\nresponse = openai.ChatCompletion.create(\r\n    model="gpt-4",\r\n    messages=[{"role": "user", "content": "Raconte-moi une blague"}]\r\n)\r\nprint(response[\'choices\'][0][\'message\'][\'content\'])\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"2-utilisation-de-langchain",children:"2. Utilisation de LangChain"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Comment \xe7a fonctionne :"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Vous utilisez la biblioth\xe8que Python/JavaScript de LangChain. Vous instanciez des classes qui appellent en interne les APIs de mod\xe8les (OpenAI, Anthropic, etc)."}),"\n",(0,r.jsx)(n.li,{children:"LangChain fournit des abstractions et utilitaires pour les workflows LLM courants."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Fonctionnalit\xe9s ajout\xe9es par LangChain :"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Cha\xeenes (Chains) :"})," Construisez des pipelines multi-\xe9tapes (ex : interroger le mod\xe8le, appeler une API de recherche, puis interroger le mod\xe8le \xe0 nouveau)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"M\xe9moire :"})," Maintient l\u2019\xe9tat de la conversation ou du contexte entre les tours."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Outils et Agents :"})," D\xe9cidez dynamiquement quels outils (recherche, calculatrices, etc.) le mod\xe8le doit utiliser."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"R\xe9cup\xe9ration (Retrieval) :"})," Int\xe9grez le RAG (g\xe9n\xe9ration augment\xe9e par la r\xe9cup\xe9ration) pour obtenir des donn\xe9es pertinentes de votre base de connaissances et les combiner avec les r\xe9ponses du LLM."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Analyseurs de sorties (Output Parsers) :"})," Convertissez facilement les r\xe9ponses en formats structur\xe9s comme JSON ou mod\xe8les Pydantic."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Int\xe9grations :"})," Connexions pr\xeates \xe0 l\u2019emploi \xe0 de nombreuses APIs LLM, magasins de vecteurs, bases de donn\xe9es, etc."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Avantages :"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"D\xe9veloppement rapide d\u2019applications complexes propuls\xe9es par LLM."}),"\n",(0,r.jsx)(n.li,{children:"R\xe9duit le code r\xe9p\xe9titif et sujet aux erreurs."}),"\n",(0,r.jsx)(n.li,{children:"Modulaire et extensible via des plugins/outils."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Inconv\xe9nients :"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Masque certains d\xe9tails\u2014moins de contr\xf4le bas niveau."}),"\n",(0,r.jsx)(n.li,{children:"D\xe9pendance suppl\xe9mentaire et taille d\u2019application potentiellement accrue."}),"\n",(0,r.jsx)(n.li,{children:"Courbe d\u2019apprentissage."}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Exemple (Chat avec m\xe9moire dans LangChain) :"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from langchain.chat_models import ChatOpenAI\r\nfrom langchain.chains import ConversationChain\r\nfrom langchain.memory import ConversationBufferMemory\r\n\r\nllm = ChatOpenAI(model="gpt-4")\r\nmemory = ConversationBufferMemory()\r\nchain = ConversationChain(llm=llm, memory=memory)\r\n\r\nresponse = chain.predict(input="Raconte-moi une blague")\r\nprint(response)\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"tableau-r\xe9capitulatif",children:"Tableau r\xe9capitulatif"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Aspect"}),(0,r.jsx)(n.th,{children:"Appel API Direct"}),(0,r.jsx)(n.th,{children:"Utilisation de LangChain"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Facilit\xe9 pour t\xe2ches simples"}),(0,r.jsx)(n.td,{children:"\xc9lev\xe9e"}),(0,r.jsx)(n.td,{children:"Bonne"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Support outils/agents"}),(0,r.jsx)(n.td,{children:"Manuel"}),(0,r.jsx)(n.td,{children:"Int\xe9gr\xe9"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Workflows multi-\xe9tapes"}),(0,r.jsx)(n.td,{children:"Manuel"}),(0,r.jsx)(n.td,{children:"Cha\xeenes en une ligne"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"M\xe9moire (\xe9tat)"}),(0,r.jsx)(n.td,{children:"Manuel"}),(0,r.jsx)(n.td,{children:"M\xe9canismes int\xe9gr\xe9s"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Analyse des sorties"}),(0,r.jsx)(n.td,{children:"Manuel"}),(0,r.jsx)(n.td,{children:"Analyseurs inclus"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Personnalisation"}),(0,r.jsx)(n.td,{children:"Contr\xf4le total"}),(0,r.jsx)(n.td,{children:"D\xe9pend du framework"})]})]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"quand-utiliser-quoi-",children:"Quand utiliser quoi ?"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"API directe"})," : T\xe2ches simples, ponctuelles ou lorsque vous avez besoin d\u2019un contr\xf4le absolu sur les requ\xeates et de d\xe9pendances minimales."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"LangChain"})," : Lorsque vous construisez des applications conversationnelles sophistiqu\xe9es, des syst\xe8mes de g\xe9n\xe9ration augment\xe9e par la r\xe9cup\xe9ration, ou des agents LLM n\xe9cessitant du cha\xeenage, de la m\xe9moire, l\u2019utilisation d\u2019outils, etc."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"En r\xe9sum\xe9 :"}),(0,r.jsx)(n.br,{}),"\n","LangChain ne remplace pas l\u2019API sous-jacente\u2014il organise et orchestre les appels \xe0 l\u2019API pour des applications IA avanc\xe9es, afin que vous puissiez en faire plus en moins de temps."]})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>a});var i=s(6540);const r={},t=i.createContext(r);function l(e){const n=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);